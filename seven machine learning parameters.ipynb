{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型参数\n",
    "import joblib\n",
    "import os\n",
    "from onekey_algo.custom.components.comp1 import plot_feature_importance, plot_learning_curve, smote_resample\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "targets = []\n",
    "os.makedirs('models', exist_ok=True)\n",
    "for l in labels:\n",
    "    new_models = okcomp.comp1.create_clf_model_none_overfit(model_names)\n",
    "    #new_models['LR'] = LogisticRegression(penalty='none', max_iter=100)\n",
    "    #new_models['SVM'] = SVC(probability=True, max_iter=100, kernel='linear')\n",
    "    new_models['RandomForest'] = RandomForestClassifier(n_estimators=50, max_depth=3,\n",
    "                                                        min_samples_split=4, random_state=0)\n",
    "    new_models['XGBoost'] = XGBClassifier(n_estimators=6, objective='binary:logistic', max_depth=3, min_child_weight=.2,\n",
    "                                              use_label_encoder=False, eval_metric='error')\n",
    "    new_models['LightGBM'] = LGBMClassifier(n_estimators=10,  max_depth=5, min_child_weight=0.5,)\n",
    "    new_models['ExtraTrees'] = ExtraTreesClassifier(n_estimators=80, max_depth=5, min_samples_split=2, random_state=0)\n",
    "    new_models['GradientBoosting'] = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "    new_models['AdaBoost'] = AdaBoostClassifier(n_estimators=15, random_state=0)\n",
    "    #new_models['MLP'] = MLPClassifier(hidden_layer_sizes=(61, 128, 64, 32), max_iter=300, solver='sgd', random_state=0)\n",
    "    model_names = list(new_models.keys())\n",
    "    new_models = list(new_models.values())\n",
    "    \n",
    "    for mn, m in zip(model_names, new_models):\n",
    "        X_train_smote, y_train_smote = X_train_sel, y_train_sel\n",
    "        # 取消下一行的注释可以使用Smote进行采样，解决样本不均衡的问题。\n",
    "        if get_param_in_cwd('use_smote', False):\n",
    "            X_train_smote, y_train_smote = smote_resample(X_train_sel, y_train_sel)\n",
    "        m.fit(X_train_smote, y_train_smote[l])\n",
    "        # 保存训练的模型\n",
    "        joblib.dump(m, f'models/{task_type}{mn}_{l}.pkl') \n",
    "        # 输出模型特征重要性，只针对高级树模型有用\n",
    "#         plot_feature_importance(m, selected_features[0], save_dir='img')\n",
    "#         plot_learning_curve(m, X_train_sel, y_train_sel, title=f'Learning Curve {mn}')\n",
    "#         plt.savefig(f\"img/Rad_{mn}_learning_curve.svg\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "    targets.append(new_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83dc410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14a994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb0456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
